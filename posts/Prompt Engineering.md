---
tags:
  - dev
  - llm
  - prompt
  - ai
---
## 기초 기법
---
### Few Shot Examples
- 몇 가지 예시를 제공하는 기법
- 답변의 포맷을 정의하는 데 유용하다
- 다양한 예제를 제공하는 것이 좋다
```
[질문]
내가 제시하는 문장을 아래 예시처럼 바꿔줘. 

오늘 본 영화는 별로였어 

예시 
- 나는 오늘 학교에 간다 -> 저 오늘 학교에 가요 
- 오늘 뭐 먹지? -> 오늘 뭐 먹으면 좋을까요? 
- 지금 출발하자 -> 지금 출발하시죠

[답변]
오늘 본 영화는 별로였어 -> 오늘 본 영화는 별로였네요
```
### Chain of Thought
- 답을 내기 위한 생간의 과정을 예시로 주는 기법 
- LLM은 산술연산 등 일부 기능에 약하기 때문에 과정을 차근차근 알려주는 것이 도움이 된다
```
[질문]

4 x 5 + 6 x 5 를 계산한 답이 뭐야?

예시
100 + 200 x 3의 계산 결과는 700이야. 왜냐하면 사칙연산에서 곱셈을 먼저하고 덧셈을 나중에 해야해. 따라서 200 x 3의 결과인 600에 100을 더해서 700이 답이되는 거야.

[답변]
4 x 5 + 6 x 5의 계산 결과를 확인하면, 먼저 곱셈을 수행합니다. 따라서:

- 4×5=204×5=20
- 6×5=306×5=30

그런 다음 두 결과를 더합니다:

- 20+30=5020+30=50

따라서, 4×5+6×54×5+6×5의 계산 결과는 50입니다.
```
### Zero Shot COT
- 질문 끝에 '차근차근 생각해보자' 등의 문구를 추가하여, Chain of Thought 식의 답변을 유도하는 기법
- OpenAI의 경우 기본적으로 이러한 답변 절차를 거친다
```
[질문]
오늘은 2024년 5월 13일 월요일이야. 10년 전 오늘은 몇월 며칠 무슨 요일일까? 순차적으로 생각해보자.

[답변]
오늘은 2024년 5월 13일 월요일이므로, 10년 전의 날짜를 계산하기 위해서는 2024년에서 10년을 빼면 2014년이 됩니다. 따라서 10년 전의 날짜는 2014년 5월 13일입니다.

다음으로, 2014년 5월 13일의 요일을 확인해야 합니다. 이를 계산하기 위해 일반적으로 그레고리력에서는 요일이 400년 주기로 반복되며, 100년마다 하루씩 밀립니다 (단, 400년은 예외). 10년은 하루가 밀리지 않을 정도로 짧으므로, 다음 규칙을 적용할 수 있습니다:

- 1년이 지날 때마다 요일은 하루씩 늦어집니다.
- 윤년의 경우에는 하루가 추가로 늦어집니다.

2024년은 윤년이므로 2024년 2월 29일이 존재하며, 2024년 5월 13일부터 거슬러 올라가 보면:

- 2024년은 윤년이므로 (월요일 - 2일) = 토요일
- 2023년은 평년이므로 (토요일 - 1일) = 금요일
- (생략)
- 2015년은 평년이므로 (수요일 - 1일) = 화요일
- 2014년은 평년이므로 (화요일 - 1일) = 월요일

따라서 2014년 5월 13일은 월요일이었습니다.
```
### Selection Inference
- 컨텍스트를 제공하고 해당 컨텍스트 내에서 답변하도록 유도하는 기법
```
[질문]
프롬프트가 뭐야? 아래 주어진 컨텍스트에서 추출해서 답변해줘. 

LLM이란? 대형 언어 모델(Large language model, LLM) 또는 거대 언어 모델은 수많은 파라미터(보통 수십억 웨이트 이상)를 보유한 인공 신경망으로 구성되는 언어 모델이다. 자기 지도 학습이나 반자기지도학습을 사용하여 레이블링되지 않은 상당한 양의 텍스트로 훈련된다.
(생략)
프롬프트는 개발자가 정보를 분석하고 토큰화하기 위해 대규모 언어 모델 LLM에 제공하는 정보로 프롬프트는 기본적으로 다양한 사용 사례에서 LLM에 도움이 되는 학습 데이터 입니다. 더 정확한 프롬프트를 받을수록 LLM은 다음 단어를 더 잘 예측하고 정확한 문장을 구성할 수 있습니다. 따라서 딥러닝 AI의 적절한 학습을 위해서는 적절한 프롬프트를 선택하는 것이 중요하다.

[답변]
프롬프트는 대규모 언어 모델(LLM)에 정보를 분석하고 토큰화하기 위해 제공하는 정보입니다. 프롬프트는 기본적으로 LLM이 학습 데이터로 활용하며, 다양한 사용 사례에서 모델의 성능을 개선하는 데 도움이 됩니다. 더 정확한 프롬프트를 받을수록 LLM은 다음 단어를 더 잘 예측하고, 정확한 문장을 구성할 수 있습니다. 따라서 적절한 프롬프트의 선택은 딥러닝 AI의 학습 과정에서 매우 중요합니다.
```
### List Of Most
- 최초 주어진 복잡한 컨텍스트에서 질문을 쪼개서 답변을 받고 이를 다시 더 넓은 범위의 질문에 대입하는 기법
- COT와 selection inference를 합친 형태이다
- 예를 들어, 문제를 해결하기 위한 질문을 생성해보라고 질의하고, 해당 질문을 프롬프트에 다시 넣어서 답변을 받는다
### ReAct
- 어떤 상황에서 어떤 도구를 사용할 지 알려주는 프롬프트와 해당 프롬프트를 이용하는 법에 대한 예시 프롬프트를 조합하여 작업별로 실행할 액션을 선택하는 기법
- 주로 외부 API, 검색엔진, 이미지 생성 도구 등과 연동할 때 유용하다
```
[실행계획 부분]
생각, 행동, 관찰 단계를 번갈아가며 질문 응답 작업을 수행한다. 
생각: 현재 상황에 대해서 추론한다
행동: 
- search[entity] : 위키백과에서 엔티티를 검색하고 첫째 문단을 반환한다
- lookup[keyword] : 현재 문단에서 키워드를 포함하는 문장을 반환한다
- finish[answer] : 답을 반환하고 작업을 마친다

[예시 부분]
질문: 대한민국 여의도의 면적은 축구장의 몇 배 크기인가?
생각: 대한민국 여의도를 검색하고 면적에 대한 정보를 얻은 다음, 축구장을 검색하고 면적에 대한 정보를 얻고, 그 다음 여의도의 면적을 축구장의 면적으로 나누어 값을 구해야 한다.
행동1: search [대한민국 여의도]
관찰1: 여의도는 대한민국의 금융, 정치의 중심지 입니다.
생각: 여의도에 대한 정보는 찾았으나 면적에 대한 정보가 없습니다. 면적에 대한 정보를 찾아야 합니다.
행동2: lookup [면적]
관찰2: 여의도의 면적은 XX 제곱미터라고 합니다. 이제 축구장의 면적을 확인해야 합니다.
(생략)
행동N: finish [XX 배]

```
### Self Evaluation
- LLM이 내놓은 결과를 LLM 스스로 평가하게 해서 오류를 잡거나 결과를 향상시키는 기법
```
[질문1]
3+1x10/2 는 얼마인가?
[답변1]
XX입니다

[질문2]
답변을 맞게 했는지 생각해보고 틀렸다면 틀린 이유를 설명하시오. (설명만 작성하고 부가적인 말은 하지 말 것)
[답변2]
수식을 계산 과정은 다음과 같습니다.
- 곱셈을 먼저 계산합니다. 
- 나눗셈을 계산합니다.
- 덧셈을 계산합니다.
답은 8입니다.

[질문3]
당신의 평가를 참고하여 처음 질문에 대한 답을 구하시오.
[답변3]
8
```
## 기타 테크닉
---
### 예시를 제공하고 생각하게 만든다 
- Expert Prompting: 특정 도메인의 전문가로서의 롤을 지정해주는 것
- According to wikipedia: 위키피디아를 참조해서 답변하라고 알려주는 것
- Retrieval Augmented Generation(RAG): 답변의 정확도를 높이기 위해 사용자의 요청과 관련된 지식을 검색 컴포넌트에서 가져와 프롬프트 컨텍스트로 제공하는 방법
### 전략을 짜고 스스로 평가하게 만든다
- Tree of thought: tree 구조로 답변을 생성해서 중간 단계의 진행상황을 스스로 평가하여 생각 트리를 확장, 조정하는 방법
- Plan and Solve Prompting: COT, SC 기법 사용 시 중간 문제 풀이 단계가 누락되고 답변에 잘못되는 경우가 있음 -> 전체 작업을 더 작은 하위 작업으로 계획을 세우고 계획에 따라 하위 작업을 수행하가나 평가하면서 전체 문제를 푸는 기법 (List of most와 달리 풀어야할 하위 문제를 모두 생성해두고 문제를 푼다)
- Automatic Prompt engineer:  프롬프트에 `<INSERT>`라는 빈칸을 만들고 생성결과를 함께 주면서 스스로 채우도록 하는 기법 (주로 fine tuning단게에서 사용)
## 생성조건
---
### Token
- 언어모델에서 텍스트를 입력하거나 출력하는 기본 요소
- LLM에서 구현하는 토크나이저에 따라 같은 단어라도 토큰이 다를 수있음
- 통상 한글에 대한 토큰 사용이 비효율적이기 때문에 토근 사용 최적화가 필요함
	- 프롬프트를 영어로 작성
	- 입출력을 번역하여 사용(번역된 컨텍스트를 사용하거나 영어로 출력시킨 후 번역)
### Context Window
- 문맥을 판단하거나 다음 단어를 예측하기 위해 참고하는 토큰의 범위
- 언어 모델이 다룰 수 있는 최대 토큰 수를 말할 때 사용하기도 함
- GPT-3.5의 경우 약 4k, 4의 경우는 약 8k임
### 생성옵션
- Temperature: 
	- 모델이 다음 토큰 후보중에서 출력할 토큰을 선택하는 방식
	- 값이 높을 수록 더 무작위적(창의적)인 답변을 함
	- 값이 낮을 수록 더 일관된 답변을 함
- Top P, Top K: 주로 Temperature와 혼합해서 적용하여 무작위성을 제한할 때 사용
- Maximum length: 생성할 최대 토큰 수를 설정 (단, 입력 프롬프트 토큰 수와 생성 토큰수가 모델의 최대 토근 수를 넘지 않도록 설정 해야함)
- Frequency Penalty: 같은 토큰을 반복하면 패널티를 줘서 같은 표현을 제한함
- Presence Penalty: 한 번 이상 샘플링 된 토큰에 패널티를 줘서 동일한 개념이나 아이디어를 제한함
- Stop sequence: 특정 문구를 설정하고 해당 문구가 나오면 생성을 중단 (과거에는 무의미한 반복 문구가 많았으나 최근에는 LLM 성능이 좋아져서 잘 사용하지 않음)
- Injection Start: 생성하기 전에 특정 문구를 삽입하여 생성
## 자연어 처리 태스크
---
### Text Generation
- Language Translation
- Style Translation
- Editing and Rewriting: 텍스트의 변경해서 새로 생성 (예, 텍스트에 존재하는 주민등록번호를 마스킹처리)
- Summarization
### Text Analysis
- Named Entity Recognition: 텍스트에서 특정 정보를 식별
```
보스턴 차 사건은 보스턴 항구에서 1773년 12월 16일에 발생했습니다. 
-> 사건명: 보스턴 차 사건
-> 장소: 보스턴 항구
-> 일시: 1773년 12월 16일
```
- Sentiment Recognition: 긍정, 부정, 중립 등 텍스트의 감정 상태를 판단
- Document Classification: 텍스트를 사전에 정의된 카테고리로 분류 (뉴스를 정치, 경제 등으로 분류 등)
- Topic Modeling: 문서 집합에서 주제를 발견 (코딩, 부트캠프, 테스트 등의 단어가 등장하는 텍스트들을 주고 해당 텍스트들이 어떤 주제와 관련있는지 판단하라고 지시하여 개발자양성코스와 관련 있음을 확인)
- Similarity Evaluation: 두 텍스트 사이의 유사성을 판단
- Question Answering: 주어진 텍스트에서 질문에 대한 정보를 추출
## Acting & Formatting
---
- acting: LLM에게 질문할 때 role을 설정하여 원하는 답변을 받도록 유도 (temperature를 낮추면 더 role에 맞는 답변을 받을 수도 있음)
- formatting: LLM은 장황하게 답변하는 경향이 있으므로, 출력형식 지정해줘야 하는 경우가 많음
	- 리스트, key-pair, 마크다운, 테이블 등
	- 포맷의 샘플을 주면 더 정확한 결과를 받을 수 있음
	- 포매팅을 통해 답변의 정확도를 더 올릴 수 있음 (아래 예시의 경우, 답변을 할 때 타입을 먼저 작성하고 이를 기반으로 answer를 하므로 답변 자체에서 체이닝효과를 얻을 수 있음)
```
user : 주어진 문장이 인사인지 감정상태인지 분류해. 인사라면 인사를 받아주고, 감정상태라면 그에 대한 답변을 해줘. 출력포맷은 다음과 같이 json으로 해줘.
"""
{
	type: {인사 | 감정상태}
	answer: {답변}
}
"""
```
## Prompt Chaining
---
일련의 프롬프트 및 답변을 순서대로 연결하여 복잡한 태스크를 수행하는 기법 (Self-Consistency, Selection-Inference, ReAct 등 고수준 프롬프트 엔지니어링은 모두 이 방법을 사용한다)
## 좋은 프롬프트 작성법
---
- 항상 같은 방법이 동일한 결과를 낼 수 없다는 점을 인지
- 자연어로 프로그래밍한다고 생각하고 자세한 입,출력, 예시를 제공하는 것이 좋음
- 컨텍스트가 길어질 수록 중간 내용을 무시하는 경향이 있으므로 주의
- 지시문을 반복적으로 사용하거나 위치를 바꾸거나 단어를 바꿔보는 등의 노력이 필요함
- 반복해서 개선하는 것이 가장 중요하다
## 모델 선정 기준
---
- 비용: 
	- 보통 입력 토큰보다 출력 토큰 수에 따라 비용이 커진다. 
	- 모델별로 토크나이저를 통해 샘플 결과로 추정해야한다.
- 속도
- 정확도
	- 정확도 대비 비용 증가 폭이 크기 때문에 적절한 모델 선택 필요
	- 벤치마크의 점수는 신
	- 뢰성이 떨어지므로 여러번의 테스트를 통한 경험적 판단이 중요
- 경향성
	- 정확한 정보 제공이 필요한게 아니라면 각 모델의 답변 경향을 보고 판단할 수도 있음
	- 단, 모델 업데이트마다 변경되므로 주의
- 안정성
- API 안정성
	- 대부분 안정성이 높지 않아서 failover 전략을 적절히 구성해야함
	- 특히 모델 업데이트시 장애가 많이 발생함
- 보안
	- openAI는 apikey 외 다른 보안체계가 제공되지 않으므로, 보안에 민감한 경우 Azure나 GCP 등 사설 네트워크 서비스를 이용하는 것이 좋음
	- 대부분의 LLM 회사들은 api를 통해 들어오는 데이터는 학습에 사용하지 않음. (단, 악의적 공격에 대비해 30일 정도의 로그를 남긴다고 알려져있음)
	- 극도의 민감 데이터를 사용해 격리된 온프레미스 환경이 필요한 경우, 커스텀 LLM을 사용해야 함(운영비, 학습비가 매우 크고 성능이 떨어질 수 있으므로 비용을 충분히 예상해야함)
## Function Calling
---
- 2024.05.15 기준 Chat GPT에서만 제공
- GPT 모델에 함수를 설정해두고 사용자 요청이 해당 함수가 필요할 때 호출함 (함수와 파라미터를 json형식으로 응답)
- 프롬프트 인젝션에 취약하기 때문에 주의필요(정상적인 파라미터로 호출되었는지, 민감정보는 파라미터 설정에 없는지 등 확인 필요)
- 호출오류가 있을 수 있음 
	- GPT가 설정하지 않은 함수라도 호출 될 수 있음 (ADD만 정의했는데, DELETE를 추론해서 호출) 
	- 요청사항을 잘 못 해석해 잘못된 파라미터를 설정해서 호출할 수 있음
- 오류와 보안상의 문제가 있을 수 있기 때문에 User에게 항상 액션을 확인을 받고 실행시키도록 해야
- 예시
	- name: 반환할 함수명
	- description: GPT가 사용자의 메시지를 해석해서 적힌 내용과 일치하면 함수를 반환
	- parameter: 함수 호출 시 필요한 파라미터
		- required: 함수 호출에 필수적인 파라미터로, 사용자 메시지에 해당 정보가 없으면 GPT가 알려줌
![[Pasted image 20240515225630.png]]
## Appendinx
---
- 생성형 AI 개발 프로세스 이해하기: https://www.itworld.co.kr/news/337110